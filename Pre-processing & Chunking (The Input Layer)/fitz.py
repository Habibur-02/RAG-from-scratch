# -*- coding: utf-8 -*-
"""RAG From scratch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_JdQTQXUkrAGTZAyYNUsHcvh5B6mfhnt
"""

!pip install pymupdf tqdm spacy
!python -m spacy download en_core_web_sm

# Download PDF file
import os
import requests

# Get PDF document
pdf_path = "human-nutrition-text.pdf"

# Download PDF if it doesn't already exist
if not os.path.exists(pdf_path):
  print("File doesn't exist, downloading...")

  # The URL of the PDF you want to download
  url = "https://pressbooks.oer.hawaii.edu/humannutrition2/open/download?type=pdf"

  # The local filename to save the downloaded file
  filename = pdf_path

  # Send a GET request to the URL
  response = requests.get(url)

  # Check if the request was successful
  if response.status_code == 200:
      # Open a file in binary write mode and save the content to it
      with open(filename, "wb") as file:
          file.write(response.content)
      print(f"The file has been downloaded and saved as {filename}")
  else:
      print(f"Failed to download the file. Status code: {response.status_code}")
else:
  print(f"File {pdf_path} exists.")

pdf_path
import fitz  # PyMuPDF
from tqdm.auto import tqdm

def text_formatter(text: str) -> str:
    """
    Performs minor formatting on text.
    """
    cleaned_text = text.replace("\n", " ").strip()
    print(cleaned_text)
    cleaned_text = " ".join(cleaned_text.split())
    return cleaned_text
text_formatter('My name is Aasif. sdhsjdhdj dkjfdjh \n dsfsdy ')

doc = fitz.open(pdf_path)
type(doc)
dir(doc)
doc.get_page_numbers
type(doc[43])

doc[49].get_text()
dir(doc)

# for i in doc:
#   if i=='page 0 of human-nutrition-text.pdf':
#     break
#   print(i)
doc[0].get_text()
doc
def open_pdf(pdf_path):
  document=fitz.open(pdf_path)
  for page_number, page in tqdm(enumerate(document)):

    if(page_number == 48):
      print(page.get_text())
      break

open_pdf(pdf_path)

image_list=doc[48].get_images()
image_list

for img_index, img in enumerate(image_list):
        xref = img[0]
        base_image = doc.extract_image(xref)
        image_bytes = base_image["image"]

        with open(f"image{48}_{img_index}.png", "wb") as f:
            f.write(image_bytes)

import fitz
from datasets import load_dataset
import pandas as pd

# ১. বেঞ্চমার্ক ডেটাসেট লোড করা (Hugging Face থেকে)
print("Loading Benchmark Dataset...")
dataset = load_dataset("PatronusAI/financebench", split="train")

# # ২. আপনার RAG অপ্টিমাইজড ফাংশন (যেখানে আপনি আপনার এক্সপেরিমেন্ট করবেন)
# def my_optimized_rag(question, doc_path):
#     # এখানে আপনার fitz এর কোড থাকবে
#     doc = fitz.open(doc_path)

#     # এক্সপেরিমেন্ট: সাধারণ টেক্সট বনাম টেবিল এক্সট্রাকশন
#     # tabs = page.find_tables() ... আপনার লজিক এখানে

#     context = "পিডিএফ থেকে আপনার খুঁজে বের করা সেরা তথ্য"

#     # এই কনটেক্সটটি পরে LLM (যেমন GPT-4 বা Llama-3) কে পাঠানো হবে
#     return context

# # ৩. এক্সপেরিমেন্ট শুরু (প্রথম ৫টি প্রশ্ন নিয়ে টেস্ট)
# results = []
# for i in range(5):
#     item = dataset[i]
#     question = item['question']
#     actual_answer = item['answer']
#     doc_link = item['doc_link'] # FinanceBench এ সরাসরি পিডিএফ লিংক থাকে

#     # আপনার সিস্টেম থেকে উত্তর আনা
#     # নোট: এখানে 'my_pdf.pdf' আপনার ডাউনলোড করা ফাইল হতে হবে
#     predicted_context = my_optimized_rag(question, pdf_path)

#     results.append({
#         "Question": question,
#         "Actual Answer": actual_answer,
#         "Retrieved Context": predicted_context
#     })

# # ৪. ফলাফল দেখা
# df_results = pd.DataFrame(results)
# print(df_results)
dataset

# প্রথম রো-এর সব তথ্য দেখা
first_row = dataset[0]

print("Question:", first_row['question'])
print("-" * 30)
print("Answer:", first_row['answer'])
print("-" * 30)
print("Source PDF Link:", first_row['doc_link'])
dataset

dataset[0]









page=doc[12]
tabs = page.find_tables()

for i, table in enumerate(tabs):
    # টেবিলটিকে একটি Pandas DataFrame হিসেবে পেতে পারেন
    df = table.to_pandas()
    print(f"Table {i+1}:")
    print(df)

    # অথবা সাধারণ লিস্ট হিসেবে দেখতে চাইলে:
    # print(table.extract())

for i, page in enumerate(doc):
  tabs = page.find_tables()
  if tabs.tables:
      print(f"✅ পেজ নম্বর {i + 1}-এ {len(tabs.tables)}টি টেবিল পাওয়া গেছে।")

      # টেবিলগুলো পান্ডাস ফ্রেম হিসেবে দেখা
      for i, table in enumerate(tabs.tables):
          df = table.to_pandas()
          print(f"--- টেবিল {i+1} ---")
          print(df.head()) # টেবিলের প্রথম ৫টি সারি দেখাচ্ছে



def open_and_read_pdf(pdf_path: str) -> list[dict]:
    """
    Opens a PDF file, reads its text content page by page, and collects statistics.

    Parameters:
        pdf_path (str): The file path to the PDF document to be opened and read.

    Returns:
        list[dict]: A list of dictionaries, each containing the page number
        (adjusted), character count, word count, sentence count, token count, and the extracted text
        for each page.
    """

    doc = fitz.open(pdf_path)  # open a document
    pages_and_texts = []
    for page_number, page in tqdm(enumerate(doc)):  # iterate the document pages
        text = page.get_text()   # get plain text encoded as UTF-8
        text = text_formatter(text)
        pages_and_texts.append({"page_number": page_number - 41,  # adjust page numbers since our PDF starts on page 42
                                "page_char_count": len(text),
                                "page_word_count": len(text.split(" ")),
                                "page_sentence_count_raw": len(text.split(". ")),
                                "page_token_count": len(text) / 4,  # 1 token = ~4 chars, see: https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them
                                "text": text})
    return pages_and_texts

pages_and_texts = open_and_read_pdf(pdf_path=pdf_path)
# pages_and_texts[:2]



"""#PyPDF2, pdfminer, fitz/PyMuPDF USE


1.   Extracting Tables
2.   Extract Image


1.   Equation(As a block, As a image)







"""

# fitz
!pip install pymupdf

pdf_path='paper1.pdf'
doc = fitz.open(pdf_path)
doc[0].get_text()
doc[1].get_text()
doc[2].get_text()
doc[3].get_text()
# doc[4].get_text()
doc[3].get_images()
page=doc[3]
blocks = page.get_text("dict")["blocks"]
blocks

image_list=doc[5].get_images()
image_list

for img_index, img in enumerate(image_list):
        xref = img[0]
        base_image = doc.extract_image(xref)
        image_bytes = base_image["image"]

        with open(f"image{3}_{img_index}.png", "wb") as f:
            f.write(image_bytes)

import fitz
import os

def extract_images_with_metadata(pdf_path, output_dir="extracted_images1"):
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    doc = fitz.open(pdf_path)
    image_metadata = []

    for page_num in range(len(doc)):
        page = doc[page_num]
        image_list = page.get_images(full=True)

        for img_index, img in enumerate(image_list):
            xref = img[0]
            base_image = doc.extract_image(xref)
            image_bytes = base_image["image"]
            image_ext = base_image["ext"]

            # ইমেজ ফাইল সেভ করা
            img_name = f"page_{page_num+1}_img_{img_index}.{image_ext}"
            img_path = os.path.join(output_dir, img_name)

            with open(img_path, "wb") as f:
                f.write(image_bytes)

            # মেটাডেটা সংগ্রহ (RAG এর জন্য)
            image_metadata.append({
                "page": page_num + 1,
                "path": img_path,
                "width": base_image["width"],
                "height": base_image["height"],
                "colorspace": base_image["colorspace"]
            })

    return image_metadata

# ব্যবহার বিধি:
metadata = extract_images_with_metadata("paper1.pdf")
print(f"Total images extracted: {len(metadata)}")

"""Queen 2.5B for extracting images"""

import fitz # PyMuPDF

def crop_equation_blocks(pdf_path, page_num):
    doc = fitz.open(pdf_path)
    page = doc[page_num]

    # "dict" ব্যবহার করলে প্রতিটি ব্লকের স্থানাঙ্ক (BBox) পাওয়া যায়
    blocks = page.get_text("dict")["blocks"]

    for i, b in enumerate(blocks):
        # সাধারণ টেক্সট থেকে আলাদা গাণিতিক চিহ্ন বা লজিক খুঁজুন
        if b['type'] == 0:  # Text block
            text = "".join([span["text"] for line in b["lines"] for span in line["spans"]])

            # ইকুয়েশন ব্লকের সাধারণ বৈশিষ্ট্য (যেমন: (1) নম্বর থাকা বা বিশেষ চিহ্ন)
            if "L(θ)" in text or "=" in text and i > 5:
                # ব্লকের স্থানাঙ্ক অনুযায়ী ক্রপ করুন
                pix = page.get_pixmap(clip=b["bbox"])
                pix.save(f"equation_page_{page_num}_{i}.png")
                print(f"Saved equation block {i} as image.")

crop_equation_blocks("paper1.pdf", 3) # ৪ নম্বর পেজ

!pip install -U transformers accelerate pillow torch torchvision

from transformers import AutoModelForCausalLM, AutoProcessor
import torch
from PIL import Image

model_id = "microsoft/Phi-3.5-vision-instruct"

# কোলাবে GPU চেক করা
device = "cuda" if torch.cuda.is_available() else "cpu"

# মডেল লোড করা (এরর ছাড়া)
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    device_map=device,
    trust_remote_code=True,
    torch_dtype="auto",
    _attn_implementation="sdpa" # flash_attention_2 এর বদলে এটি দিন
)

processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)

import fitz

def get_perfect_crop(pdf_path, output_name):
    doc = fitz.open(pdf_path)
    page = doc[3] # পেজ ৪

    # রেজোলিউশন বাড়ানোর জন্য জুম সেট করা
    mat = fitz.Matrix(2, 2)

    # সমীকরণ ১ এর সঠিক অবস্থান (বাম কলামের নিচের দিকে)
    # x0 (বাম), y0 (উপর), x1 (ডান), y1 (নিচ)
    equation_rect = fitz.Rect(580, 560, 900, 610)

    # ক্রপ এবং সেভ
    pix = page.get_pixmap(matrix=mat, clip=equation_rect)
    pix.save(output_name)
    print(f"Saved: {output_name}")

get_perfect_crop("paper1.pdf", "equation_1_fixed.png")





import fitz
import json

doc = fitz.open("paper1.pdf")
page = doc[3]  # ৪ নম্বর পেজ (index 3)

# ১. টেক্সট এবং এর অবস্থান (Coordinates) বের করা
blocks = page.get_text("dict")["blocks"]

page_data = {
    "page_num": 4,
    "text_blocks": [],
    "images": []
}

for b in blocks:
    if b['type'] == 0:  # এটি টেক্সট ব্লক
        block_text = ""
        for line in b["lines"]:
            for span in line["spans"]:
                block_text += span["text"]

        # সমীকরণ শনাক্ত করার একটি সাধারণ উপায় (যেমন: যেখানে (1) বা (2) নম্বর আছে)
        if "(1)" in block_text or "L(θ)" in block_text:
            page_data["text_blocks"].append({
                "type": "equation",
                "bbox": b["bbox"],
                "content": block_text.strip()
            })
        else:
            page_data["text_blocks"].append({
                "type": "text",
                "bbox": b["bbox"],
                "content": block_text.strip()
            })

    elif b['type'] == 1:  # এটি ইমেজ ব্লক
        page_data["images"].append({
            "bbox": b["bbox"],
            "type": "image"
        })

# ছবি আলাদাভাবে সেভ করা (রেফারেন্সের জন্য)
for i, img in enumerate(page.get_images(full=True)):
    xref = img[0]
    pix = fitz.Pixmap(doc, xref)
    if pix.n - pix.alpha > 3: # CMYK হলে RGB তে রূপান্তর
        pix = fitz.Pixmap(fitz.csRGB, pix)
    pix.save(f"page4_image_{i}.png")

print(json.dumps(page_data, indent=2))

import fitz  # PyMuPDF
import os

def process_pdf_for_rag(pdf_path):
    # PDF ওপেন করা
    doc = fitz.open(pdf_path)

    # ইমেজ সেভ করার জন্য ফোল্ডার তৈরি
    if not os.path.exists("extracted_images"):
        os.makedirs("extracted_images")

    rag_data = []

    for page_num in range(len(doc)):
        page = doc[page_num]

        # ১. টেক্সট এবং মেটাডেটা এক্সট্রাকশন
        text = page.get_text("text")

        # ২. ইমেজ এক্সট্রাকশন এবং মেটাডেটা
        images = page.get_images(full=True)
        image_info = []
        for img_index, img in enumerate(images):
            xref = img[0]
            base_image = doc.extract_image(xref)
            image_bytes = base_image["image"]
            image_ext = base_image["ext"]

            image_filename = f"extracted_images/page{page_num+1}_img{img_index}.{image_ext}"
            with open(image_filename, "wb") as f:
                f.write(image_bytes)

            image_info.append({
                "filename": image_filename,
                "format": image_ext,
                "width": base_image["width"],
                "height": base_image["height"]
            })

        # ৩. মেটাডেটা অবজেক্ট তৈরি (RAG এর জন্য)
        page_metadata = {
            "source": pdf_path,
            "page_number": page_num + 1,
            "content": text,
            "images": image_info,
            "equations_found": "Check content for LaTeX symbols like $ or \\"  # গাণিতিক চিহ্ন খোঁজার লজিক
        }

        rag_data.append(page_metadata)

        print(f"--- Page {page_num + 1} Processed ---")
        print(f"Extracted {len(text)} characters and {len(image_info)} images.")

    return rag_data

# আপনার ডাউনলোড করা PDF ফাইলের নাম এখানে দিন
pdf_url = "paper1.pdf"
# (আগের মেসেজের লিঙ্ক থেকে ফাইলটি ডাউনলোড করে কোডস্পেসে সেভ করে নিন)

extracted_data = process_pdf_for_rag(pdf_url)

# উদাহরন হিসেবে প্রথম পেজের মেটাডেটা দেখা
import json
print(json.dumps(extracted_data[0], indent=2))





































